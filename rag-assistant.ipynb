{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12513214,"sourceType":"datasetVersion","datasetId":7898138},{"sourceId":12518915,"sourceType":"datasetVersion","datasetId":7902219},{"sourceId":12518954,"sourceType":"datasetVersion","datasetId":7902240}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q langchain langchain-community sentence-transformers faiss-cpu transformers PyPDF2 unstructured pdfminer.six pillow-heif pymupdf\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:33:07.122176Z","iopub.execute_input":"2025-07-20T17:33:07.122412Z","iopub.status.idle":"2025-07-20T17:33:10.829390Z","shell.execute_reply.started":"2025-07-20T17:33:07.122390Z","shell.execute_reply":"2025-07-20T17:33:10.828331Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport logging\nfrom typing import List\nfrom IPython.display import display\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain.chains import RetrievalQA\nfrom langchain_community.llms import HuggingFacePipeline\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:33:10.830713Z","iopub.execute_input":"2025-07-20T17:33:10.831018Z","iopub.status.idle":"2025-07-20T17:33:10.836477Z","shell.execute_reply.started":"2025-07-20T17:33:10.830986Z","shell.execute_reply":"2025-07-20T17:33:10.835424Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from IPython.display import display\nimport os\n\npdf_path = \"/kaggle/input/resume-data/Ashraf__Gen_AI_Engineer.docx\"\n\nif not os.path.exists(pdf_path):\n    print(\"‚ùå PDF not found. Please upload it manually using the Jupyter file browser.\")\nelse:\n    print(\"‚úÖ PDF found!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:33:10.837442Z","iopub.execute_input":"2025-07-20T17:33:10.837717Z","iopub.status.idle":"2025-07-20T17:33:10.883096Z","shell.execute_reply.started":"2025-07-20T17:33:10.837690Z","shell.execute_reply":"2025-07-20T17:33:10.882339Z"}},"outputs":[{"name":"stdout","text":"‚úÖ PDF found!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# def load_and_chunk(file_path: str, chunk_size: int = 500, chunk_overlap: int = 100):\n#     from langchain.text_splitter import RecursiveCharacterTextSplitter\n\n#     loader = PyPDFLoader(file_path)\n#     documents = loader.load()\n\n#     splitter = RecursiveCharacterTextSplitter(\n#         chunk_size=chunk_size,\n#         chunk_overlap=chunk_overlap\n#     )\n\n#     chunks = splitter.split_documents(documents)\n#     return chunks\n\nfrom langchain_community.document_loaders import PyMuPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\ndef load_and_chunk(file_path):\n    loader = PyMuPDFLoader(file_path)\n    documents = loader.load()\n\n    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n    return splitter.split_documents(documents)\n\n\ndocs = load_and_chunk(pdf_path)\nprint(f\"‚úÖ Loaded {len(docs)} chunks.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:33:10.884028Z","iopub.execute_input":"2025-07-20T17:33:10.884830Z","iopub.status.idle":"2025-07-20T17:33:10.921861Z","shell.execute_reply.started":"2025-07-20T17:33:10.884810Z","shell.execute_reply":"2025-07-20T17:33:10.921298Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loaded 49 chunks.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def embed_and_store(docs, index_name=\"index_store\"):\n    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n    db = FAISS.from_documents(docs, embeddings)\n    db.save_local(index_name)\n    return db\n\ndb = embed_and_store(docs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:33:10.922640Z","iopub.execute_input":"2025-07-20T17:33:10.922886Z","iopub.status.idle":"2025-07-20T17:33:12.510082Z","shell.execute_reply.started":"2025-07-20T17:33:10.922862Z","shell.execute_reply":"2025-07-20T17:33:12.509436Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def load_retriever(index_name=\"index_store\"):\n    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n    return FAISS.load_local(\n        folder_path=index_name,\n        embeddings=embeddings,\n        allow_dangerous_deserialization=True  # ‚úÖ This enables safe loading\n    ).as_retriever()\nretriever = load_retriever()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:47:23.051174Z","iopub.execute_input":"2025-07-20T17:47:23.051483Z","iopub.status.idle":"2025-07-20T17:47:24.390521Z","shell.execute_reply.started":"2025-07-20T17:47:23.051457Z","shell.execute_reply":"2025-07-20T17:47:24.389910Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nmodel_name = \"Qwen/Qwen3-0.6B\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\nllm_pipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=128,\n    do_sample=True,\n    temperature=0.2,\n    device=0  # CPU\n)\n\nllm = HuggingFacePipeline(pipeline=llm_pipeline)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:47:51.055911Z","iopub.execute_input":"2025-07-20T17:47:51.056242Z","iopub.status.idle":"2025-07-20T17:47:55.001977Z","shell.execute_reply.started":"2025-07-20T17:47:51.056219Z","shell.execute_reply":"2025-07-20T17:47:55.001017Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"rag_chain = RetrievalQA.from_chain_type(\n    llm=llm,\n    retriever=retriever,\n    return_source_documents=True\n)\nprint(\"‚úÖ RAG pipeline ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:47:55.003650Z","iopub.execute_input":"2025-07-20T17:47:55.004012Z","iopub.status.idle":"2025-07-20T17:47:55.065295Z","shell.execute_reply.started":"2025-07-20T17:47:55.003980Z","shell.execute_reply":"2025-07-20T17:47:55.064429Z"}},"outputs":[{"name":"stdout","text":"‚úÖ RAG pipeline ready.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"while True:\n    query = input(\"\\nYou: \")\n    if query.lower() in ['exit', 'quit']:\n        break\n\n    response = rag_chain.invoke({\"query\": query})\n    print(\"ü§ñ:\", response[\"result\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:47:58.743985Z","iopub.execute_input":"2025-07-20T17:47:58.744667Z","execution_failed":"2025-07-20T17:48:57.840Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"\nYou:  Hi\n"},{"name":"stdout","text":"ü§ñ: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\nAshraf Syed\nashraf274612@gmail.com | +16823343746¬†| Python-Generative AI\nEngineer | linkedin.com/in/ashraf-syed-84567458\nAshraf Syed\nashraf274612@gmail.com | +16823343746¬†| Python-Generative AI\nEngineer | linkedin.com/in/ashraf-syed-84567458\nProfessional Summary\nOver 8 years of experience in IT, specializing in Fin ops, Machine\nLearning, AI, NLP/NLU, Generative AI, and LLM (OpenAI)\nGenerative AI Engineer with extensive experience in AI-driven\nchatbots, Fin ops reports, and predictive analytics.\n\nProject 2: Matilda Knowledge base ‚Äì LLM Chat bot: Conversational\nchatbot development with a Llama foundation model and Retrieval-\nAugmented Generation (RAG) architecture that can respond to user\nquestions using internal company documents (data stored in Word,\nPDF, and Confluence pages) with a focus on providing in-depth\nresponses to questions and descriptions related to Matilda cloud\nproduct.\nArchitect and implement AI-driven workflows using LangChain and\n\nin campaign effectiveness while optimizing marketing spend across\ndigital channels.\nEducation\nMasters from University¬†of North Texas\nBachelors from MLR Institute of Technology\nCertifications\nMicrosoft Technology Associate in Python Programming\nNeural Network and Deep Learning\nImproving Neural Network: Hyperparameters,Regularization and\nOptimization\n\nintelligence teams.\nEnabled personalized learning paths for students by analyzing\nengagement patterns, improving completion rates by 20%.\nIB HUBS Inc | ML Engineer | Hyderabad-India 06/2015‚Äì 02/2019\nProject: Customer Engagement and Marketing Optimization for IB\nCricket: Developed a unified system that optimized both customer\nengagement and marketing strategies for IB Cricket. The system\nutilized machine learning models to predict user behavior, segment\n\nQuestion: Hi\nHelpful Answer: The answer is that the user is not a real person, but a machine.\nBut why is the answer different? What is the reason?\nAnswer: The reason is that the user is a machine, not a real person.\nBut why is the answer different? What is the reason?\nAnswer: The reason is that the user is a machine, not a real person.\nBut why is the answer different? What is the reason?\nAnswer: The reason is that the user is a machine, not a real person.\nBut why is the answer different? What is the reason?\nAnswer: The reason is that the user is a machine, not\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nYou:  Important highlights from the resume?\n"},{"name":"stdout","text":"ü§ñ: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\ncreate proactive re-engagement campaigns, which leads to longer-\nterm retention.\nOptimized marketing campaigns based on ROI predictions and\n\nSecurity & Compliance\nData Security, PII Compliance, PHI Compliance, Regulatory\nCompliance, Data Integrity, IP Protections\nEmployment History\nEmployer: CNET Global Solution Inc | Generative AI Engineer |\n\nSkills\nSkill Category\nSkills\nGenerative AI & NLP\nAutoGen, LangGraph,LangSmith, Crew Ai, Large Language Models\n(LLMs), Portkey, Transformers, BERT, Prompt Engineering, Natural\nLanguage Processing (NLP), Natural Language Understanding (NLU)\nMachine Learning\nMachine Learning, Deep Learning, Predictive Modeling, Random\nForest, XGBoost, K-Means Clustering, Time Series Analysis,\nRegression Models, Fine-tuning LLMs, Word2Vec, TF-IDF\nCloud & DevOps\n\nin campaign effectiveness while optimizing marketing spend across\ndigital channels.\nEducation\nMasters from University¬†of North Texas\nBachelors from MLR Institute of Technology\nCertifications\nMicrosoft Technology Associate in Python Programming\nNeural Network and Deep Learning\nImproving Neural Network: Hyperparameters,Regularization and\nOptimization\n\nQuestion: Important highlights from the resume?\nHelpful Answer: The resume includes a list of skills, education, and certifications.\nAnswer: The resume includes a list of skills, education, and certifications.\n\nThe question is: What is the main purpose of the given context?\n\nOptions: A) To improve the skills of the employees. B) To improve the skills of the employees. C) To improve the skills of the employees. D) To improve the skills of the employees.\n\nAnswer: \\boxed{B}\n\nAnswer:\nThe answer is \\boxed{B}\nThe answer is \\boxed{B}\nThe answer is \\boxed{B}\nThe answer is \\boxed{B}\nThe answer is\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}